{
    "data" : [
        "\nR version 3.3.1 (2016-06-21) -- \"Bug in Your Hair\"\nCopyright (C) 2016 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\n",
        "Type 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n",
        "WARNING: Your CRAN mirror is set to \"http://cran.rstudio.com/\" which has an insecure (non-HTTPS) URL. The repository was likely specified in .Rprofile or Rprofile.site so if you wish to change it you may need to edit one of those files. You should either switch to a repository that supports HTTPS or change your RStudio options to not require HTTPS downloads.\n\nTo learn more and/or disable this warning message see the \"Use secure download method for HTTP\" option in Tools -> Global Options -> Packages.\n",
        "> ",
        "xgboost:::xgb.train",
        "function (params = list(), data, nrounds, watchlist = list(), \n    obj = NULL, feval = NULL, verbose = 1, print_every_n = 1L, \n    early_stopping_rounds = NULL, maximize = NULL, save_period = NULL, \n    save_name = \"xgboost.model\", xgb_model = NULL, callbacks = list(), \n    ...) \n{\n    check.deprecation(...)\n    params <- check.booster.params(params, ...)\n    check.custom.obj()\n    check.custom.eval()\n    dtrain <- data\n    if (class(dtrain) != \"xgb.DMatrix\") \n        stop(\"second argument dtrain must be xgb.DMatrix\")\n",
        "    if (length(watchlist) > 0) {\n        if (typeof(watchlist) != \"list\" || !all(sapply(watchlist, \n            class) == \"xgb.DMatrix\")) \n            stop(\"watchlist must be a list of xgb.DMatrix elements\")\n        evnames <- names(watchlist)\n        if (is.null(evnames) || any(evnames == \"\")) \n            stop(\"each element of the watchlist must have a name tag\")\n    }\n    params <- c(params, list(silent = ifelse(verbose > 1, 0, \n        1)))\n    print_every_n <- max(as.integer(print_every_n), 1L)\n    if (!has.callbacks(callbacks, \"cb.print.evaluation\") && verbose) {\n",
        "        callbacks <- add.cb(callbacks, cb.print.evaluation(print_every_n))\n    }\n    evaluation_log <- list()\n    if (verbose > 0 && !has.callbacks(callbacks, \"cb.evaluation.log\") && \n        length(watchlist) > 0) {\n        callbacks <- add.cb(callbacks, cb.evaluation.log())\n    }\n    if (!is.null(save_period) && !has.callbacks(callbacks, \"cb.save.model\")) {\n        callbacks <- add.cb(callbacks, cb.save.model(save_period, \n            save_name))\n    }\n    stop_condition <- FALSE\n    if (!is.null(early_stopping_rounds) && !has.callbacks(callbacks, \n",
        "        \"cb.early.stop\")) {\n        callbacks <- add.cb(callbacks, cb.early.stop(early_stopping_rounds, \n            maximize = maximize, verbose = verbose))\n    }\n    cb <- categorize.callbacks(callbacks)\n    handle <- xgb.Booster(params, append(watchlist, dtrain), \n        xgb_model)\n    bst <- xgb.handleToBooster(handle)\n    num_class <- max(as.numeric(NVL(params[[\"num_class\"]], 1)), \n        1)\n    num_parallel_tree <- max(as.numeric(NVL(params[[\"num_parallel_tree\"]], \n        1)), 1)\n    niter_skip <- 0\n",
        "    if (!is.null(xgb_model)) {\n        niter_skip <- as.numeric(xgb.attr(bst, \"niter\")) + 1\n        if (length(niter_skip) == 0) {\n            niter_skip <- xgb.ntree(bst)%/%(num_parallel_tree * \n                num_class)\n        }\n    }\n    rank <- 0\n    begin_iteration <- niter_skip + 1\n    end_iteration <- niter_skip + nrounds\n    for (iteration in begin_iteration:end_iteration) {\n        for (f in cb$pre_iter) f()\n        xgb.iter.update(bst$handle, dtrain, iteration - 1, obj)\n        bst_evaluation <- numeric(0)\n",
        "        if (length(watchlist) > 0) \n            bst_evaluation <- xgb.iter.eval(bst$handle, watchlist, \n                iteration - 1, feval)\n        xgb.attr(bst$handle, \"niter\") <- iteration - 1\n        for (f in cb$post_iter) f()\n        if (stop_condition) \n            break\n    }\n    for (f in cb$finalize) f(finalize = TRUE)\n    bst <- xgb.Booster.check(bst, saveraw = TRUE)\n    bst$niter = end_iteration\n    if (length(evaluation_log) > 0 && nrow(evaluation_log) > \n        0) {\n        if (class(xgb_model) == \"xgb.Booster\" && !is.null(xgb_model$evaluation_log) && \n",
        "            all.equal(colnames(evaluation_log), colnames(xgb_model$evaluation_log))) {\n            evaluation_log <- rbindlist(list(xgb_model$evaluation_log, \n                evaluation_log))\n        }\n        bst$evaluation_log <- evaluation_log\n    }\n    bst$call <- match.call()\n    bst$params <- params\n    bst$callbacks <- callbacks\n    return(bst)\n}\n<environment: namespace:xgboost>\n",
        "> ",
        "xgboost:::categorize.callbacks",
        "function (cb_list) \n{\n    list(pre_iter = Filter(function(x) {\n        pre <- attr(x, \"is_pre_iteration\")\n        !is.null(pre) && pre\n    }, cb_list), post_iter = Filter(function(x) {\n        pre <- attr(x, \"is_pre_iteration\")\n        is.null(pre) || !pre\n    }, cb_list), finalize = Filter(function(x) {\n        \"finalize\" %in% names(formals(x))\n    }, cb_list))\n}\n<environment: namespace:xgboost>\n",
        "> ",
        "?Filter",
        "> ",
        "xgb.cv",
        "Error: object 'xgb.cv' not found\n",
        "> ",
        "xgboost:::xgb.cv",
        "function (params = list(), data, nrounds, nfold, label = NULL, \n    missing = NA, prediction = FALSE, showsd = TRUE, metrics = list(), \n    obj = NULL, feval = NULL, stratified = TRUE, folds = NULL, \n    verbose = TRUE, print_every_n = 1L, early_stopping_rounds = NULL, \n    maximize = NULL, callbacks = list(), ...) \n{\n    check.deprecation(...)\n    params <- check.booster.params(params, ...)\n    for (m in metrics) params <- c(params, list(eval_metric = m))\n    check.custom.obj()\n    check.custom.eval()\n    if (class(data) == \"xgb.DMatrix\") \n",
        "        labels <- getinfo(data, \"label\")\n    if (is.null(labels)) \n        stop(\"Labels must be provided for CV either through xgb.DMatrix, or through 'label=' when 'data' is matrix\")\n    if (!is.null(folds)) {\n        if (class(folds) != \"list\" || length(folds) < 2) \n            stop(\"'folds' must be a list with 2 or more elements that are vectors of indices for each CV-fold\")\n        nfold <- length(folds)\n    }\n    else {\n        if (nfold <= 1) \n            stop(\"'nfold' must be > 1\")\n        folds <- generate.cv.folds(nfold, nrow(data), stratified, \n",
        "            label, params)\n    }\n    params <- c(params, list(silent = 1))\n    print_every_n <- max(as.integer(print_every_n), 1L)\n    if (!has.callbacks(callbacks, \"cb.print.evaluation\") && verbose) {\n        callbacks <- add.cb(callbacks, cb.print.evaluation(print_every_n))\n    }\n    evaluation_log <- list()\n    if (!has.callbacks(callbacks, \"cb.evaluation.log\")) {\n        callbacks <- add.cb(callbacks, cb.evaluation.log())\n    }\n    stop_condition <- FALSE\n    if (!is.null(early_stopping_rounds) && !has.callbacks(callbacks, \n",
        "        \"cb.early.stop\")) {\n        callbacks <- add.cb(callbacks, cb.early.stop(early_stopping_rounds, \n            maximize = maximize, verbose = verbose))\n    }\n    if (prediction && !has.callbacks(callbacks, \"cb.cv.predict\")) {\n        callbacks <- add.cb(callbacks, cb.cv.predict(save_models = FALSE))\n    }\n    cb <- categorize.callbacks(callbacks)\n    dall <- xgb.get.DMatrix(data, label, missing)\n    bst_folds <- lapply(1:length(folds), function(k) {\n        dtest <- slice(dall, folds[[k]])\n        dtrain <- slice(dall, unlist(folds[-k]))\n",
        "        bst <- xgb.Booster(params, list(dtrain, dtest))\n        list(dtrain = dtrain, bst = bst, watchlist = list(train = dtrain, \n            test = dtest), index = folds[[k]])\n    })\n    basket <- list()\n    num_class <- max(as.numeric(NVL(params[[\"num_class\"]], 1)), \n        1)\n    num_parallel_tree <- max(as.numeric(NVL(params[[\"num_parallel_tree\"]], \n        1)), 1)\n    begin_iteration <- 1\n    end_iteration <- nrounds\n    for (iteration in begin_iteration:end_iteration) {\n        for (f in cb$pre_iter) f()\n",
        "        msg <- lapply(bst_folds, function(fd) {\n            xgb.iter.update(fd$bst, fd$dtrain, iteration - 1, \n                obj)\n            xgb.iter.eval(fd$bst, fd$watchlist, iteration - 1, \n                feval)\n        })\n        msg <- simplify2array(msg)\n        bst_evaluation <- rowMeans(msg)\n        bst_evaluation_err <- sqrt(rowMeans(msg^2) - bst_evaluation^2)\n        for (f in cb$post_iter) f()\n        if (stop_condition) \n            break\n    }\n    for (f in cb$finalize) f(finalize = TRUE)\n    ret <- list(call = match.call(), params = params, callbacks = callbacks, \n",
        "        evaluation_log = evaluation_log, niter = end_iteration, \n        folds = folds)\n    ret <- c(ret, basket)\n    class(ret) <- \"xgb.cv.synchronous\"\n    invisible(ret)\n}\n<environment: namespace:xgboost>\n",
        "> ",
        "library(xgboost)",
        "> ",
        "library(dplyr)",
        "\nAttaching package: ‘dplyr’\n\n",
        "The following object is masked from ‘package:xgboost’:\n\n    slice\n\n",
        "The following objects are masked from ‘package:stats’:\n\n    filter, lag\n\n",
        "The following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\n\n",
        "> ",
        "",
        "> ",
        "feats1 = read.csv('data/working/features/features1/feats1.csv')",
        "> ",
        "targets1 = read.csv('data/working/features/features1/targets1.csv')",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "# class weights",
        "> ",
        "cweights = c(1.35298455691,1.38684574053,1.59587388404,1.35318713948,0.347783666015,0.661081706198,1.04723628621,0.398865222651,",
        "+ ",
        "                 0.207586320237,1.50578335208,0.110181365961,1.07803284435,1.36560417316,1.17024113802,1.1933637414,1.1803704493,",
        "+ ",
        "                 1.34414875433,1.11683830693,1.08083910312,0.503152249073)",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "# train DMatrices",
        "> ",
        "#trains <- lapply(1:20, function(c) xgb.DMatrix(data=data.matrix(feats1), label=as.numeric(targets1[,c]), missing=NA))",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "# parameters",
        "> ",
        "params = list(booster = 'gbtree',",
        "+ ",
        "              objective = 'reg:logistic',",
        "+ ",
        "              eta = 0.1,",
        "+ ",
        "              subsample=1,",
        "+ ",
        "              colsample_bytree=1,",
        "+ ",
        "              max_depth=2,",
        "+ ",
        "              verbose=1,",
        "+ ",
        "              silent=1,",
        "+ ",
        "              nthread=3)",
        "> ",
        "data <- lapply(1:20, function(c) xgb.DMatrix(data=data.matrix(feats1), label=as.numeric(targets1[,c]), missing=NA))",
        "> ",
        "# folds are of length 1753 1642 1516 1537 1507 1392 1505 1668 1825 1779",
        "> ",
        "  folds = list(1:1753, 1754:3395, 3396:4911, 4912:6448, 6449:7955, 7956:9347, 9348:10852, 10853:12520, 12521:14345, 14346:16124)",
        "> ",
        "  folds = list(1:1753, 1754:3395, 3396:4911, 4912:6448, 6449:7955, 7956:9347, 9348:10852, 10853:12520, 12521:14345, 14346:16124)",
        "> ",
        "  ",
        "> ",
        "  ",
        "> ",
        "  booster_folds <- lapply(1:length(folds), function(k){",
        "+ ",
        "    test = lapply(1:20, function(c) xgboost:::slice(data[[c]], folds[[k]]))",
        "+ ",
        "    train = lapply(1:20, function(c) xgboost:::slice(data[[c]], unlist(folds[-k])))",
        "+ ",
        "    booster = lapply(1:20, function(c) xgboost:::xgb.Booster(params, list(train[[c]], test[[c]])))",
        "+ ",
        "    bf = list(train=train, test=test, booster=booster)",
        "+ ",
        "    return(bf)",
        "+ ",
        "  })",
        "> ",
        "hist = list()",
        "> ",
        "  ",
        "> ",
        "  BS <- function(preds, train){",
        "+ ",
        "    labels = lapply(1:20, function(c) getinfo(train[[c]], 'label'))",
        "+ ",
        "    err = lapply(1:20, function(c) sum(cweights[c]*(preds[[c]] - labels[[c]])^2)/length(labels[[c]]))",
        "+ ",
        "    err = sum(unlist(err))",
        "+ ",
        "    return(c('BS'=err))",
        "+ ",
        "  }",
        "> ",
        "i=1",
        "> ",
        "res <- lapply(booster_folds, function(bf){",
        "+ ",
        "      ",
        "+ ",
        "      succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(bf$booster[[c]], bf$train[[c]], i - 1, obj=NULL))",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) predict(bf$booster[[c]], bf$train[[c]]))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) predict(bf$booster[[c]], bf$test[[c]]))",
        "+ ",
        "      ",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) preds_train[[c]]/colSums(do.call('rbind', preds_train)))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) preds_test[[c]]/colSums(do.call('rbind', preds_test)))",
        "+ ",
        "      ",
        "+ ",
        "      #eval_train = BS(preds_train, bf$train); names(eval_train) = 'train-BS'",
        "+ ",
        "      #eval_test = BS(preds_test, bf$test); names(eval_test) = 'test-BS'",
        "+ ",
        "      ",
        "+ ",
        "      #rm(preds_train, preds_test, succ)",
        "+ ",
        "      #return(c(eval_train, eval_test))",
        "+ ",
        "    })",
        "> ",
        "res",
        "[[1]]\n[[1]][[1]]\n[1] TRUE\n\n[[1]][[2]]\n[1] TRUE\n\n[[1]][[3]]\n[1] TRUE\n\n[[1]][[4]]\n[1] TRUE\n\n[[1]][[5]]\n[1] TRUE\n\n[[1]][[6]]\n[1] TRUE\n\n[[1]][[7]]\n[1] TRUE\n\n[[1]][[8]]\n[1] TRUE\n\n[[1]][[9]]\n[1] TRUE\n\n[[1]][[10]]\n[1] TRUE\n\n[[1]][[11]]\n[1] TRUE\n\n[[1]][[12]]\n[1] TRUE\n\n[[1]][[13]]\n[1] TRUE\n\n[[1]][[14]]\n[1] TRUE\n\n[[1]][[15]]\n[1] TRUE\n\n[[1]][[16]]\n[1] TRUE\n\n[[1]][[17]]\n[1] TRUE\n\n[[1]][[18]]\n[1] TRUE\n\n[[1]][[19]]\n[1] TRUE\n\n[[1]][[20]]\n[1] TRUE\n\n\n[[2]]\n[[2]][[1]]\n[1] TRUE\n\n[[2]][[2]]\n[1] TRUE\n\n[[2]][[3]]\n[1] TRUE\n\n[[2]][[4]]\n",
        "[1] TRUE\n\n[[2]][[5]]\n[1] TRUE\n\n[[2]][[6]]\n[1] TRUE\n\n[[2]][[7]]\n[1] TRUE\n\n[[2]][[8]]\n[1] TRUE\n\n[[2]][[9]]\n[1] TRUE\n\n[[2]][[10]]\n[1] TRUE\n\n[[2]][[11]]\n[1] TRUE\n\n[[2]][[12]]\n[1] TRUE\n\n[[2]][[13]]\n[1] TRUE\n\n[[2]][[14]]\n[1] TRUE\n\n[[2]][[15]]\n[1] TRUE\n\n[[2]][[16]]\n[1] TRUE\n\n[[2]][[17]]\n[1] TRUE\n\n[[2]][[18]]\n[1] TRUE\n\n[[2]][[19]]\n[1] TRUE\n\n[[2]][[20]]\n[1] TRUE\n\n\n[[3]]\n[[3]][[1]]\n[1] TRUE\n\n[[3]][[2]]\n[1] TRUE\n\n[[3]][[3]]\n[1] TRUE\n\n[[3]][[4]]\n[1] TRUE\n\n[[3]][[5]]\n[1] TRUE\n\n[[3]][[6]]\n[1] TRUE\n\n[[3]][[7]]\n[1] TRUE\n\n[[3]][[8]]\n",
        "[1] TRUE\n\n[[3]][[9]]\n[1] TRUE\n\n[[3]][[10]]\n[1] TRUE\n\n[[3]][[11]]\n[1] TRUE\n\n[[3]][[12]]\n[1] TRUE\n\n[[3]][[13]]\n[1] TRUE\n\n[[3]][[14]]\n[1] TRUE\n\n[[3]][[15]]\n[1] TRUE\n\n[[3]][[16]]\n[1] TRUE\n\n[[3]][[17]]\n[1] TRUE\n\n[[3]][[18]]\n[1] TRUE\n\n[[3]][[19]]\n[1] TRUE\n\n[[3]][[20]]\n[1] TRUE\n\n\n[[4]]\n[[4]][[1]]\n[1] TRUE\n\n[[4]][[2]]\n[1] TRUE\n\n[[4]][[3]]\n[1] TRUE\n\n[[4]][[4]]\n[1] TRUE\n\n[[4]][[5]]\n[1] TRUE\n\n[[4]][[6]]\n[1] TRUE\n\n[[4]][[7]]\n[1] TRUE\n\n[[4]][[8]]\n[1] TRUE\n\n[[4]][[9]]\n[1] TRUE\n\n[[4]][[10]]\n[1] TRUE\n\n[[4]][[11]]\n[1] TRUE\n",
        "\n[[4]][[12]]\n[1] TRUE\n\n[[4]][[13]]\n[1] TRUE\n\n[[4]][[14]]\n[1] TRUE\n\n[[4]][[15]]\n[1] TRUE\n\n[[4]][[16]]\n[1] TRUE\n\n[[4]][[17]]\n[1] TRUE\n\n[[4]][[18]]\n[1] TRUE\n\n[[4]][[19]]\n[1] TRUE\n\n[[4]][[20]]\n[1] TRUE\n\n\n[[5]]\n[[5]][[1]]\n[1] TRUE\n\n[[5]][[2]]\n[1] TRUE\n\n[[5]][[3]]\n[1] TRUE\n\n[[5]][[4]]\n[1] TRUE\n\n[[5]][[5]]\n[1] TRUE\n\n[[5]][[6]]\n[1] TRUE\n\n[[5]][[7]]\n[1] TRUE\n\n[[5]][[8]]\n[1] TRUE\n\n[[5]][[9]]\n[1] TRUE\n\n[[5]][[10]]\n[1] TRUE\n\n[[5]][[11]]\n[1] TRUE\n\n[[5]][[12]]\n[1] TRUE\n\n[[5]][[13]]\n[1] TRUE\n\n[[5]][[14]]\n[1] TRUE\n\n[[5]][[15]]\n",
        "[1] TRUE\n\n[[5]][[16]]\n[1] TRUE\n\n[[5]][[17]]\n[1] TRUE\n\n[[5]][[18]]\n[1] TRUE\n\n[[5]][[19]]\n[1] TRUE\n\n[[5]][[20]]\n[1] TRUE\n\n\n[[6]]\n[[6]][[1]]\n[1] TRUE\n\n[[6]][[2]]\n[1] TRUE\n\n[[6]][[3]]\n[1] TRUE\n\n[[6]][[4]]\n[1] TRUE\n\n[[6]][[5]]\n[1] TRUE\n\n[[6]][[6]]\n[1] TRUE\n\n[[6]][[7]]\n[1] TRUE\n\n[[6]][[8]]\n[1] TRUE\n\n[[6]][[9]]\n[1] TRUE\n\n[[6]][[10]]\n[1] TRUE\n\n[[6]][[11]]\n[1] TRUE\n\n[[6]][[12]]\n[1] TRUE\n\n[[6]][[13]]\n[1] TRUE\n\n[[6]][[14]]\n[1] TRUE\n\n[[6]][[15]]\n[1] TRUE\n\n[[6]][[16]]\n[1] TRUE\n\n[[6]][[17]]\n[1] TRUE\n\n[[6]][[18]]\n[1] TRUE",
        "\n\n[[6]][[19]]\n[1] TRUE\n\n[[6]][[20]]\n[1] TRUE\n\n\n[[7]]\n[[7]][[1]]\n[1] TRUE\n\n[[7]][[2]]\n[1] TRUE\n\n[[7]][[3]]\n[1] TRUE\n\n[[7]][[4]]\n[1] TRUE\n\n[[7]][[5]]\n[1] TRUE\n\n[[7]][[6]]\n[1] TRUE\n\n[[7]][[7]]\n[1] TRUE\n\n[[7]][[8]]\n[1] TRUE\n\n[[7]][[9]]\n[1] TRUE\n\n[[7]][[10]]\n[1] TRUE\n\n[[7]][[11]]\n[1] TRUE\n\n[[7]][[12]]\n[1] TRUE\n\n[[7]][[13]]\n[1] TRUE\n\n[[7]][[14]]\n[1] TRUE\n\n[[7]][[15]]\n[1] TRUE\n\n[[7]][[16]]\n[1] TRUE\n\n[[7]][[17]]\n[1] TRUE\n\n[[7]][[18]]\n[1] TRUE\n\n[[7]][[19]]\n[1] TRUE\n\n[[7]][[20]]\n[1] TRUE\n\n\n[[8]]\n[[8]][[1]]\n[1] TRUE\n\n",
        "[[8]][[2]]\n[1] TRUE\n\n[[8]][[3]]\n[1] TRUE\n\n[[8]][[4]]\n[1] TRUE\n\n[[8]][[5]]\n[1] TRUE\n\n[[8]][[6]]\n[1] TRUE\n\n[[8]][[7]]\n[1] TRUE\n\n[[8]][[8]]\n[1] TRUE\n\n[[8]][[9]]\n[1] TRUE\n\n[[8]][[10]]\n[1] TRUE\n\n[[8]][[11]]\n[1] TRUE\n\n[[8]][[12]]\n[1] TRUE\n\n[[8]][[13]]\n[1] TRUE\n\n[[8]][[14]]\n[1] TRUE\n\n[[8]][[15]]\n[1] TRUE\n\n[[8]][[16]]\n[1] TRUE\n\n[[8]][[17]]\n[1] TRUE\n\n[[8]][[18]]\n[1] TRUE\n\n[[8]][[19]]\n[1] TRUE\n\n[[8]][[20]]\n[1] TRUE\n\n\n[[9]]\n[[9]][[1]]\n[1] TRUE\n\n[[9]][[2]]\n[1] TRUE\n\n[[9]][[3]]\n[1] TRUE\n\n[[9]][[4]]\n[1] TRUE\n\n[[9]][[5]]\n",
        "[1] TRUE\n\n[[9]][[6]]\n[1] TRUE\n\n[[9]][[7]]\n[1] TRUE\n\n[[9]][[8]]\n[1] TRUE\n\n[[9]][[9]]\n[1] TRUE\n\n[[9]][[10]]\n[1] TRUE\n\n[[9]][[11]]\n[1] TRUE\n\n[[9]][[12]]\n[1] TRUE\n\n[[9]][[13]]\n[1] TRUE\n\n[[9]][[14]]\n[1] TRUE\n\n[[9]][[15]]\n[1] TRUE\n\n[[9]][[16]]\n[1] TRUE\n\n[[9]][[17]]\n[1] TRUE\n\n[[9]][[18]]\n[1] TRUE\n\n[[9]][[19]]\n[1] TRUE\n\n[[9]][[20]]\n[1] TRUE\n\n\n[[10]]\n[[10]][[1]]\n[1] TRUE\n\n[[10]][[2]]\n[1] TRUE\n\n[[10]][[3]]\n[1] TRUE\n\n[[10]][[4]]\n[1] TRUE\n\n[[10]][[5]]\n[1] TRUE\n\n[[10]][[6]]\n[1] TRUE\n\n[[10]][[7]]\n[1] TRUE\n\n[[10]][[8]]\n[1]",
        " TRUE\n\n[[10]][[9]]\n[1] TRUE\n\n[[10]][[10]]\n[1] TRUE\n\n[[10]][[11]]\n[1] TRUE\n\n[[10]][[12]]\n[1] TRUE\n\n[[10]][[13]]\n[1] TRUE\n\n[[10]][[14]]\n[1] TRUE\n\n[[10]][[15]]\n[1] TRUE\n\n[[10]][[16]]\n[1] TRUE\n\n[[10]][[17]]\n[1] TRUE\n\n[[10]][[18]]\n[1] TRUE\n\n[[10]][[19]]\n[1] TRUE\n\n[[10]][[20]]\n[1] TRUE\n\n\n",
        "> ",
        "i=2",
        "> ",
        "res <- lapply(booster_folds, function(bf){",
        "+ ",
        "      ",
        "+ ",
        "      succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(bf$booster[[c]], bf$train[[c]], i - 1, obj=NULL))",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) predict(bf$booster[[c]], bf$train[[c]]))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) predict(bf$booster[[c]], bf$test[[c]]))",
        "+ ",
        "      ",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) preds_train[[c]]/colSums(do.call('rbind', preds_train)))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) preds_test[[c]]/colSums(do.call('rbind', preds_test)))",
        "+ ",
        "      ",
        "+ ",
        "      #eval_train = BS(preds_train, bf$train); names(eval_train) = 'train-BS'",
        "+ ",
        "      #eval_test = BS(preds_test, bf$test); names(eval_test) = 'test-BS'",
        "+ ",
        "      ",
        "+ ",
        "      #rm(preds_train, preds_test, succ)",
        "+ ",
        "      #return(c(eval_train, eval_test))",
        "+ ",
        "    })",
        "> ",
        "res",
        "[[1]]\n[[1]][[1]]\n[1] TRUE\n\n[[1]][[2]]\n[1] TRUE\n\n[[1]][[3]]\n[1] TRUE\n\n[[1]][[4]]\n[1] TRUE\n\n[[1]][[5]]\n[1] TRUE\n\n[[1]][[6]]\n[1] TRUE\n\n[[1]][[7]]\n[1] TRUE\n\n[[1]][[8]]\n[1] TRUE\n\n[[1]][[9]]\n[1] TRUE\n\n[[1]][[10]]\n[1] TRUE\n\n[[1]][[11]]\n[1] TRUE\n\n[[1]][[12]]\n[1] TRUE\n\n[[1]][[13]]\n[1] TRUE\n\n[[1]][[14]]\n[1] TRUE\n\n[[1]][[15]]\n[1] TRUE\n\n[[1]][[16]]\n[1] TRUE\n\n[[1]][[17]]\n[1] TRUE\n\n[[1]][[18]]\n[1] TRUE\n\n[[1]][[19]]\n[1] TRUE\n\n[[1]][[20]]\n[1] TRUE\n\n\n[[2]]\n[[2]][[1]]\n[1] TRUE\n\n[[2]][[2]]\n[1] TRUE\n\n[[2]][[3]]\n[1] TRUE\n\n[[2]][[4]]\n",
        "[1] TRUE\n\n[[2]][[5]]\n[1] TRUE\n\n[[2]][[6]]\n[1] TRUE\n\n[[2]][[7]]\n[1] TRUE\n\n[[2]][[8]]\n[1] TRUE\n\n[[2]][[9]]\n[1] TRUE\n\n[[2]][[10]]\n[1] TRUE\n\n[[2]][[11]]\n[1] TRUE\n\n[[2]][[12]]\n[1] TRUE\n\n[[2]][[13]]\n[1] TRUE\n\n[[2]][[14]]\n[1] TRUE\n\n[[2]][[15]]\n[1] TRUE\n\n[[2]][[16]]\n[1] TRUE\n\n[[2]][[17]]\n[1] TRUE\n\n[[2]][[18]]\n[1] TRUE\n\n[[2]][[19]]\n[1] TRUE\n\n[[2]][[20]]\n[1] TRUE\n\n\n[[3]]\n[[3]][[1]]\n[1] TRUE\n\n[[3]][[2]]\n[1] TRUE\n\n[[3]][[3]]\n[1] TRUE\n\n[[3]][[4]]\n[1] TRUE\n\n[[3]][[5]]\n[1] TRUE\n\n[[3]][[6]]\n[1] TRUE\n\n[[3]][[7]]\n[1] TRUE\n\n[[3]][[8]]\n",
        "[1] TRUE\n\n[[3]][[9]]\n[1] TRUE\n\n[[3]][[10]]\n[1] TRUE\n\n[[3]][[11]]\n[1] TRUE\n\n[[3]][[12]]\n[1] TRUE\n\n[[3]][[13]]\n[1] TRUE\n\n[[3]][[14]]\n[1] TRUE\n\n[[3]][[15]]\n[1] TRUE\n\n[[3]][[16]]\n[1] TRUE\n\n[[3]][[17]]\n[1] TRUE\n\n[[3]][[18]]\n[1] TRUE\n\n[[3]][[19]]\n[1] TRUE\n\n[[3]][[20]]\n[1] TRUE\n\n\n[[4]]\n[[4]][[1]]\n[1] TRUE\n\n[[4]][[2]]\n[1] TRUE\n\n[[4]][[3]]\n[1] TRUE\n\n[[4]][[4]]\n[1] TRUE\n\n[[4]][[5]]\n[1] TRUE\n\n[[4]][[6]]\n[1] TRUE\n\n[[4]][[7]]\n[1] TRUE\n\n[[4]][[8]]\n[1] TRUE\n\n[[4]][[9]]\n[1] TRUE\n\n[[4]][[10]]\n[1] TRUE\n\n[[4]][[11]]\n[1] TRUE\n",
        "\n[[4]][[12]]\n[1] TRUE\n\n[[4]][[13]]\n[1] TRUE\n\n[[4]][[14]]\n[1] TRUE\n\n[[4]][[15]]\n[1] TRUE\n\n[[4]][[16]]\n[1] TRUE\n\n[[4]][[17]]\n[1] TRUE\n\n[[4]][[18]]\n[1] TRUE\n\n[[4]][[19]]\n[1] TRUE\n\n[[4]][[20]]\n[1] TRUE\n\n\n[[5]]\n[[5]][[1]]\n[1] TRUE\n\n[[5]][[2]]\n[1] TRUE\n\n[[5]][[3]]\n[1] TRUE\n\n[[5]][[4]]\n[1] TRUE\n\n[[5]][[5]]\n[1] TRUE\n\n[[5]][[6]]\n[1] TRUE\n\n[[5]][[7]]\n[1] TRUE\n\n[[5]][[8]]\n[1] TRUE\n\n[[5]][[9]]\n[1] TRUE\n\n[[5]][[10]]\n[1] TRUE\n\n[[5]][[11]]\n[1] TRUE\n\n[[5]][[12]]\n[1] TRUE\n\n[[5]][[13]]\n[1] TRUE\n\n[[5]][[14]]\n[1] TRUE\n\n[[5]][[15]]\n",
        "[1] TRUE\n\n[[5]][[16]]\n[1] TRUE\n\n[[5]][[17]]\n[1] TRUE\n\n[[5]][[18]]\n[1] TRUE\n\n[[5]][[19]]\n[1] TRUE\n\n[[5]][[20]]\n[1] TRUE\n\n\n[[6]]\n[[6]][[1]]\n[1] TRUE\n\n[[6]][[2]]\n[1] TRUE\n\n[[6]][[3]]\n[1] TRUE\n\n[[6]][[4]]\n[1] TRUE\n\n[[6]][[5]]\n[1] TRUE\n\n[[6]][[6]]\n[1] TRUE\n\n[[6]][[7]]\n[1] TRUE\n\n[[6]][[8]]\n[1] TRUE\n\n[[6]][[9]]\n[1] TRUE\n\n[[6]][[10]]\n[1] TRUE\n\n[[6]][[11]]\n[1] TRUE\n\n[[6]][[12]]\n[1] TRUE\n\n[[6]][[13]]\n[1] TRUE\n\n[[6]][[14]]\n[1] TRUE\n\n[[6]][[15]]\n[1] TRUE\n\n[[6]][[16]]\n[1] TRUE\n\n[[6]][[17]]\n[1] TRUE\n\n[[6]][[18]]\n[1] TRUE",
        "\n\n[[6]][[19]]\n[1] TRUE\n\n[[6]][[20]]\n[1] TRUE\n\n\n[[7]]\n[[7]][[1]]\n[1] TRUE\n\n[[7]][[2]]\n[1] TRUE\n\n[[7]][[3]]\n[1] TRUE\n\n[[7]][[4]]\n[1] TRUE\n\n[[7]][[5]]\n[1] TRUE\n\n[[7]][[6]]\n[1] TRUE\n\n[[7]][[7]]\n[1] TRUE\n\n[[7]][[8]]\n[1] TRUE\n\n[[7]][[9]]\n[1] TRUE\n\n[[7]][[10]]\n[1] TRUE\n\n[[7]][[11]]\n[1] TRUE\n\n[[7]][[12]]\n[1] TRUE\n\n[[7]][[13]]\n[1] TRUE\n\n[[7]][[14]]\n[1] TRUE\n\n[[7]][[15]]\n[1] TRUE\n\n[[7]][[16]]\n[1] TRUE\n\n[[7]][[17]]\n[1] TRUE\n\n[[7]][[18]]\n[1] TRUE\n\n[[7]][[19]]\n[1] TRUE\n\n[[7]][[20]]\n[1] TRUE\n\n\n[[8]]\n[[8]][[1]]\n[1] TRUE\n\n",
        "[[8]][[2]]\n[1] TRUE\n\n[[8]][[3]]\n[1] TRUE\n\n[[8]][[4]]\n[1] TRUE\n\n[[8]][[5]]\n[1] TRUE\n\n[[8]][[6]]\n[1] TRUE\n\n[[8]][[7]]\n[1] TRUE\n\n[[8]][[8]]\n[1] TRUE\n\n[[8]][[9]]\n[1] TRUE\n\n[[8]][[10]]\n[1] TRUE\n\n[[8]][[11]]\n[1] TRUE\n\n[[8]][[12]]\n[1] TRUE\n\n[[8]][[13]]\n[1] TRUE\n\n[[8]][[14]]\n[1] TRUE\n\n[[8]][[15]]\n[1] TRUE\n\n[[8]][[16]]\n[1] TRUE\n\n[[8]][[17]]\n[1] TRUE\n\n[[8]][[18]]\n[1] TRUE\n\n[[8]][[19]]\n[1] TRUE\n\n[[8]][[20]]\n[1] TRUE\n\n\n[[9]]\n[[9]][[1]]\n[1] TRUE\n\n[[9]][[2]]\n[1] TRUE\n\n[[9]][[3]]\n[1] TRUE\n\n[[9]][[4]]\n[1] TRUE\n\n[[9]][[5]]\n",
        "[1] TRUE\n\n[[9]][[6]]\n[1] TRUE\n\n[[9]][[7]]\n[1] TRUE\n\n[[9]][[8]]\n[1] TRUE\n\n[[9]][[9]]\n[1] TRUE\n\n[[9]][[10]]\n[1] TRUE\n\n[[9]][[11]]\n[1] TRUE\n\n[[9]][[12]]\n[1] TRUE\n\n[[9]][[13]]\n[1] TRUE\n\n[[9]][[14]]\n[1] TRUE\n\n[[9]][[15]]\n[1] TRUE\n\n[[9]][[16]]\n[1] TRUE\n\n[[9]][[17]]\n[1] TRUE\n\n[[9]][[18]]\n[1] TRUE\n\n[[9]][[19]]\n[1] TRUE\n\n[[9]][[20]]\n[1] TRUE\n\n\n[[10]]\n[[10]][[1]]\n[1] TRUE\n\n[[10]][[2]]\n[1] TRUE\n\n[[10]][[3]]\n[1] TRUE\n\n[[10]][[4]]\n[1] TRUE\n\n[[10]][[5]]\n[1] TRUE\n\n[[10]][[6]]\n[1] TRUE\n\n[[10]][[7]]\n[1] TRUE\n\n[[10]][[8]]\n[1]",
        " TRUE\n\n[[10]][[9]]\n[1] TRUE\n\n[[10]][[10]]\n[1] TRUE\n\n[[10]][[11]]\n[1] TRUE\n\n[[10]][[12]]\n[1] TRUE\n\n[[10]][[13]]\n[1] TRUE\n\n[[10]][[14]]\n[1] TRUE\n\n[[10]][[15]]\n[1] TRUE\n\n[[10]][[16]]\n[1] TRUE\n\n[[10]][[17]]\n[1] TRUE\n\n[[10]][[18]]\n[1] TRUE\n\n[[10]][[19]]\n[1] TRUE\n\n[[10]][[20]]\n[1] TRUE\n\n\n",
        "> ",
        "for(i in 3:30){",
        "+ ",
        "    ",
        "+ ",
        "    res <- lapply(booster_folds, function(bf){",
        "+ ",
        "      ",
        "+ ",
        "      succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(bf$booster[[c]], bf$train[[c]], i - 1, obj=NULL))",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) predict(bf$booster[[c]], bf$train[[c]]))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) predict(bf$booster[[c]], bf$test[[c]]))",
        "+ ",
        "      ",
        "+ ",
        "      ",
        "+ ",
        "      #preds_train = lapply(1:20, function(c) preds_train[[c]]/colSums(do.call('rbind', preds_train)))",
        "+ ",
        "      #preds_test = lapply(1:20, function(c) preds_test[[c]]/colSums(do.call('rbind', preds_test)))",
        "+ ",
        "      ",
        "+ ",
        "      #eval_train = BS(preds_train, bf$train); names(eval_train) = 'train-BS'",
        "+ ",
        "      #eval_test = BS(preds_test, bf$test); names(eval_test) = 'test-BS'",
        "+ ",
        "      ",
        "+ ",
        "      #rm(preds_train, preds_test, succ)",
        "+ ",
        "      #return(c(eval_train, eval_test))",
        "+ ",
        "    })",
        "+ ",
        "    ",
        "+ ",
        "    #res = do.call('rbind', res) %>% as.data.frame",
        "+ ",
        "    #res = c(mean(res[,1]), sd(res[,2]), mean(res[,2]), sd(res[,2]))",
        "+ ",
        "    #print(res)",
        "+ ",
        "    #hist[[i]] = res",
        "+ ",
        "    print(i)",
        "+ ",
        "  }",
        "[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n[1] 12\n[1] 13\n[1] 14\n[1] 15\n[1] 16\n[1] 17\n[1] 18\n[1] 19\n[1] 20\n[1] 21\n[1] 22\n[1] 23\n[1] 24\n[1] 25\n[1] 26\n[1] 27\n[1] 28\n[1] 29\n[1] 30\n",
        "> ",
        "res <- lapply(booster_folds, function(bf){",
        "+ ",
        "      ",
        "+ ",
        "      #succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(bf$booster[[c]], bf$train[[c]], i - 1, obj=NULL))",
        "+ ",
        "      ",
        "+ ",
        "      preds_train = lapply(1:20, function(c) predict(bf$booster[[c]], bf$train[[c]]))",
        "+ ",
        "      preds_test = lapply(1:20, function(c) predict(bf$booster[[c]], bf$test[[c]]))",
        "+ ",
        "      ",
        "+ ",
        "      ",
        "+ ",
        "      preds_train = lapply(1:20, function(c) preds_train[[c]]/colSums(do.call('rbind', preds_train)))",
        "+ ",
        "      preds_test = lapply(1:20, function(c) preds_test[[c]]/colSums(do.call('rbind', preds_test)))",
        "+ ",
        "      ",
        "+ ",
        "      eval_train = BS(preds_train, bf$train); names(eval_train) = 'train-BS'",
        "+ ",
        "      eval_test = BS(preds_test, bf$test); names(eval_test) = 'test-BS'",
        "+ ",
        "      ",
        "+ ",
        "      rm(preds_train, preds_test, succ)",
        "+ ",
        "      return(c(eval_train, eval_test))",
        "+ ",
        "    })",
        "Warning messages:\n",
        "1: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "2: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "3: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "4: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "5: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "6: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "7: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "8: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "9: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "10: ",
        "In rm(preds_train, preds_test, succ) :",
        " object 'succ' not found\n",
        "> ",
        "res",
        "[[1]]\n train-BS   test-BS \n0.2418313 0.2023882 \n\n[[2]]\n train-BS   test-BS \n0.2363938 0.2516242 \n\n[[3]]\n train-BS   test-BS \n0.2348301 0.2622246 \n\n[[4]]\n train-BS   test-BS \n0.2408049 0.2202920 \n\n[[5]]\n train-BS   test-BS \n0.2386148 0.2370785 \n\n[[6]]\n train-BS   test-BS \n0.2356213 0.2539828 \n\n[[7]]\n train-BS   test-BS \n0.2354987 0.2732240 \n\n[[8]]\n train-BS   test-BS \n0.2356991 0.2579357 \n\n[[9]]\n train-BS   test-BS \n0.2350774 0.2679147 \n\n[[10]]\n train-BS   test-BS \n0.2378983 0.2432884 \n\n",
        "> ",
        "res = do.call('rbind', res) %>% as.data.frame",
        "> ",
        "res = c(mean(res[,1]), sd(res[,2]), mean(res[,2]), sd(res[,2]))",
        "> ",
        "res",
        "[1] 0.23722697 0.02201611 0.24699532 0.02201611\n",
        "> ",
        "bf =booster_folds[[1]]",
        "> ",
        "preds_train = lapply(1:20, function(c) predict(bf$booster[[c]], bf$train[[c]]))",
        "> ",
        "",
        "> ",
        "2.2*10",
        "[1] 22\n",
        "> ",
        "xgb.cv",
        "function (params = list(), data, nrounds, nfold, label = NULL, \n    missing = NA, prediction = FALSE, showsd = TRUE, metrics = list(), \n    obj = NULL, feval = NULL, stratified = TRUE, folds = NULL, \n    verbose = TRUE, print_every_n = 1L, early_stopping_rounds = NULL, \n    maximize = NULL, callbacks = list(), ...) \n{\n    check.deprecation(...)\n    params <- check.booster.params(params, ...)\n    for (m in metrics) params <- c(params, list(eval_metric = m))\n    check.custom.obj()\n    check.custom.eval()\n    if (class(data) == \"xgb.DMatrix\") \n",
        "        labels <- getinfo(data, \"label\")\n    if (is.null(labels)) \n        stop(\"Labels must be provided for CV either through xgb.DMatrix, or through 'label=' when 'data' is matrix\")\n    if (!is.null(folds)) {\n        if (class(folds) != \"list\" || length(folds) < 2) \n            stop(\"'folds' must be a list with 2 or more elements that are vectors of indices for each CV-fold\")\n        nfold <- length(folds)\n    }\n    else {\n        if (nfold <= 1) \n            stop(\"'nfold' must be > 1\")\n        folds <- generate.cv.folds(nfold, nrow(data), stratified, \n",
        "            label, params)\n    }\n    params <- c(params, list(silent = 1))\n    print_every_n <- max(as.integer(print_every_n), 1L)\n    if (!has.callbacks(callbacks, \"cb.print.evaluation\") && verbose) {\n        callbacks <- add.cb(callbacks, cb.print.evaluation(print_every_n))\n    }\n    evaluation_log <- list()\n    if (!has.callbacks(callbacks, \"cb.evaluation.log\")) {\n        callbacks <- add.cb(callbacks, cb.evaluation.log())\n    }\n    stop_condition <- FALSE\n    if (!is.null(early_stopping_rounds) && !has.callbacks(callbacks, \n",
        "        \"cb.early.stop\")) {\n        callbacks <- add.cb(callbacks, cb.early.stop(early_stopping_rounds, \n            maximize = maximize, verbose = verbose))\n    }\n    if (prediction && !has.callbacks(callbacks, \"cb.cv.predict\")) {\n        callbacks <- add.cb(callbacks, cb.cv.predict(save_models = FALSE))\n    }\n    cb <- categorize.callbacks(callbacks)\n    dall <- xgb.get.DMatrix(data, label, missing)\n    bst_folds <- lapply(1:length(folds), function(k) {\n        dtest <- slice(dall, folds[[k]])\n        dtrain <- slice(dall, unlist(folds[-k]))\n",
        "        bst <- xgb.Booster(params, list(dtrain, dtest))\n        list(dtrain = dtrain, bst = bst, watchlist = list(train = dtrain, \n            test = dtest), index = folds[[k]])\n    })\n    basket <- list()\n    num_class <- max(as.numeric(NVL(params[[\"num_class\"]], 1)), \n        1)\n    num_parallel_tree <- max(as.numeric(NVL(params[[\"num_parallel_tree\"]], \n        1)), 1)\n    begin_iteration <- 1\n    end_iteration <- nrounds\n    for (iteration in begin_iteration:end_iteration) {\n        for (f in cb$pre_iter) f()\n",
        "        msg <- lapply(bst_folds, function(fd) {\n            xgb.iter.update(fd$bst, fd$dtrain, iteration - 1, \n                obj)\n            xgb.iter.eval(fd$bst, fd$watchlist, iteration - 1, \n                feval)\n        })\n        msg <- simplify2array(msg)\n        bst_evaluation <- rowMeans(msg)\n        bst_evaluation_err <- sqrt(rowMeans(msg^2) - bst_evaluation^2)\n        for (f in cb$post_iter) f()\n        if (stop_condition) \n            break\n    }\n    for (f in cb$finalize) f(finalize = TRUE)\n    ret <- list(call = match.call(), params = params, callbacks = callbacks, \n",
        "        evaluation_log = evaluation_log, niter = end_iteration, \n        folds = folds)\n    ret <- c(ret, basket)\n    class(ret) <- \"xgb.cv.synchronous\"\n    invisible(ret)\n}\n<environment: namespace:xgboost>\n",
        "> ",
        "lapply(list(list(1), list(2)), function(i) ptin(i))",
        "Error in FUN(X[[i]], ...) : could not find function \"ptin\"\n",
        "> ",
        "lapply(list(list(1), list(2)), function(i) print(i))",
        "[[1]]\n[1] 1\n\n[[1]]\n[1] 2\n\n[[1]]\n[[1]][[1]]\n[1] 1\n\n\n[[2]]\n[[2]][[1]]\n[1] 2\n\n\n",
        "> ",
        "require(dplyr)",
        "> ",
        "",
        "> ",
        "# load",
        "> ",
        "",
        "> ",
        "accel <- read.csv('data/raw_data/public_data/train/00001/acceleration.csv')",
        "> ",
        "target <- read.csv('data/raw_data/public_data/train/00001/targets.csv')",
        "> ",
        "pir <- read.csv('data/raw_data/public_data/train/00001/pir.csv')",
        "> ",
        "video_hallway <- read.csv('data/raw_data/public_data/train/00001/video_hallway.csv')",
        "> ",
        "video_kitchen <- read.csv('data/raw_data/public_data/train/00001/video_kitchen.csv')",
        "> ",
        "video_living_room <- read.csv('data/raw_data/public_data/train/00001/video_living_room.csv')",
        "> ",
        "View(accel)",
        "> ",
        "View(target)",
        "> ",
        "which(target$a_ascend > 0)",
        " [1]  708  709  710  711  712  713  714 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116\n[25] 1117 1118 1119\n",
        "> ",
        "require(ggplot2)",
        "Loading required package: ggplot2\n",
        "> ",
        "end = which(target$a_ascend > 0)",
        "> ",
        "e=end[1]",
        "> ",
        "tmp = accel[which(accel$t < e & accel$t >= e-2),]",
        "> ",
        "  plot(tmp$x)",
        "> ",
        "plot(x = tmp$t, y = tmp$x)",
        "> ",
        "ggplot(x = tmp$t, y = tmp$x)",
        "> ",
        "for (e in end){",
        "+ ",
        "  tmp = accel[which(accel$t < e & accel$t >= e-2),]",
        "+ ",
        "  plot(x = tmp$t, y = tmp$x)",
        "+ ",
        "}",
        "> ",
        "end = which(target$a_ascend > 0)",
        "> ",
        "for (e in end){",
        "+ ",
        "  tmp = accel[which(accel$t < e & accel$t >= e-2),]",
        "+ ",
        "  plot(x = tmp$t, y = tmp$x, type='l')",
        "+ ",
        "}",
        "> ",
        "tmp",
        "             t     x      y      z Kitchen_AP Lounge_AP Upstairs_AP Study_AP\n22004 1117.040 0.888 -0.334  0.220       -102        NA         -56       NA\n22005 1117.090 0.910 -0.334  0.224         NA        NA         -60       NA\n22006 1117.140 1.070 -0.360  0.216         NA        NA         -60       NA\n22007 1117.190 1.286 -0.382  0.160         NA        NA         -60       NA\n22008 1117.240 1.368 -0.428  0.140         NA        NA         -60       NA\n22009 1117.290 1.106 -0.274  0.184         NA        NA",
        "         -61       NA\n22010 1117.340 0.824 -0.290  0.144         NA        NA         -61       NA\n22011 1117.390 0.886 -0.180  0.088         NA        NA         -61       NA\n22012 1117.440 0.798 -0.184  0.108         NA        NA         -61       NA\n22013 1117.490 0.844 -0.212  0.070         NA        NA         -67       NA\n22014 1117.540 0.862 -0.232  0.014         NA        NA         -67       NA\n22015 1117.590 0.856 -0.266 -0.008         NA        NA         -67       NA\n22016 1117.640 0.806 -0.264  0.006",
        "         NA        NA         -67       NA\n22017 1117.691 0.766 -0.288 -0.040         NA        NA         -65       NA\n22018 1117.741 0.760 -0.272  0.006         NA        NA         -65       NA\n22019 1117.791 0.864 -0.378  0.006         NA        NA         -65       NA\n22020 1117.841 0.862 -0.456  0.030         NA        NA         -65       NA\n22021 1117.891 0.928 -0.520  0.056         NA        NA         -67       NA\n22022 1117.941 1.016 -0.504  0.112         NA        NA         -67       NA\n22023 1117.991",
        " 1.096 -0.496  0.144         NA        NA         -67       NA\n22024 1118.041 1.432 -0.474  0.038         NA        NA         -67       NA\n22025 1118.091 1.394 -0.420  0.078         NA        NA         -66       NA\n22026 1118.141 0.892 -0.224  0.188         NA        NA         -66       NA\n22027 1118.191 0.820 -0.174  0.128         NA        NA         -66       NA\n22028 1118.241 0.924 -0.154  0.030         NA        NA         -66       NA\n22029 1118.291 0.888 -0.168  0.060         NA        NA         -61",
        "       NA\n22030 1118.341 0.824 -0.254  0.112         NA        NA         -61       NA\n22031 1118.391 0.782 -0.292  0.142         NA        NA         -61       NA\n22032 1118.441 0.690 -0.306  0.178         NA        NA         -61       NA\n22033 1118.491 0.718 -0.288  0.168         NA        NA         -66       NA\n22034 1118.541 0.776 -0.240  0.166         NA        NA         -66       NA\n22035 1118.591 0.766 -0.264  0.146         NA        NA         -66       NA\n22036 1118.641 0.792 -0.292  0.184         NA",
        "        NA         -66       NA\n22037 1118.692 0.830 -0.298  0.206         NA        NA         -73       NA\n22038 1118.742 0.908 -0.346  0.192         NA        NA         -73       NA\n22039 1118.792 1.058 -0.392  0.184         NA        NA         -73       NA\n22040 1118.842 1.134 -0.376  0.166         NA        NA         -73       NA\n22041 1118.892 1.310 -0.322  0.120         NA        NA         -70       NA\n22042 1118.942 1.186 -0.314  0.134         NA        NA         -70       NA\n22043 1118.992 0.910",
        " -0.346  0.188         NA        NA         -70       NA\n",
        "> ",
        "end",
        " [1]  708  709  710  711  712  713  714 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116\n[25] 1117 1118 1119\n",
        "> ",
        "xgboost:::cb.cv.predict()",
        "function (env = parent.frame(), finalize = FALSE) \n{\n    if (finalize) \n        return(finalizer(env))\n}\n<environment: 0x85177b8>\nattr(,\"call\")\nxgboost:::cb.cv.predict()\nattr(,\"name\")\n[1] \"cb.cv.predict\"\n",
        "> ",
        "xgboost:::cb.cv.predict",
        "function (save_models = FALSE) \n{\n    finalizer <- function(env) {\n        if (is.null(env$basket) || is.null(env$bst_folds)) \n            stop(\"'cb.cv.predict' callback requires 'basket' and 'bst_folds' lists in its calling frame\")\n        N <- nrow(env$data)\n        pred <- ifelse(env$num_class > 1, matrix(NA_real_, N, \n            env$num_class), rep(NA_real_, N))\n        ntreelimit <- NVL(env$basket$best_ntreelimit, env$end_iteration * \n            env$num_parallel_tree)\n        for (fd in env$bst_folds) {\n",
        "            pr <- predict(fd$bst, fd$watchlist[[2]], ntreelimit = ntreelimit, \n                reshape = TRUE)\n            if (is.matrix(pred)) {\n                pred[fd$index, ] <- pr\n            }\n            else {\n                pred[fd$index] <- pr\n            }\n        }\n        env$basket$pred <- pred\n        if (save_models) {\n            env$basket$models <- lapply(env$bst_folds, function(fd) {\n                xgb.attr(fd$bst, \"niter\") <- env$end_iteration - \n                  1\n                xgb.Booster.check(xgb.handleToBooster(fd$bst), \n",
        "                  saveraw = TRUE)\n            })\n        }\n    }\n    callback <- function(env = parent.frame(), finalize = FALSE) {\n        if (finalize) \n            return(finalizer(env))\n    }\n    attr(callback, \"call\") <- match.call()\n    attr(callback, \"name\") <- \"cb.cv.predict\"\n    callback\n}\n<environment: namespace:xgboost>\n",
        "> ",
        "predict",
        "function (object, ...) \nUseMethod(\"predict\")\n<bytecode: 0x2be7268>\n<environment: namespace:stats>\n",
        "> ",
        "xgboost:::predict.xgb.Booster",
        "function (object, newdata, missing = NA, outputmargin = FALSE, \n    ntreelimit = NULL, predleaf = FALSE, reshape = FALSE, ...) \n{\n    object <- xgb.Booster.check(object, saveraw = FALSE)\n    if (class(newdata) != \"xgb.DMatrix\") \n        newdata <- xgb.DMatrix(newdata, missing = missing)\n    if (is.null(ntreelimit)) \n        ntreelimit <- NVL(object$best_ntreelimit, 0)\n    if (ntreelimit < 0) \n        stop(\"ntreelimit cannot be negative\")\n    option <- 0L + 1L * as.logical(outputmargin) + 2L * as.logical(predleaf)\n",
        "    ret <- .Call(\"XGBoosterPredict_R\", object$handle, newdata, \n        option[1], as.integer(ntreelimit), PACKAGE = \"xgboost\")\n    if (length(ret)%%nrow(newdata) != 0) \n        stop(\"prediction length \", length(ret), \" is not multiple of nrows(newdata) \", \n            nrow(newdata))\n    npred_per_case <- length(ret)/nrow(newdata)\n    if (predleaf) {\n        len <- nrow(newdata)\n        ret <- if (length(ret) == len) {\n            matrix(ret, ncol = 1)\n        }\n        else {\n            t(matrix(ret, ncol = len))\n",
        "        }\n    }\n    else if (reshape && npred_per_case > 1) {\n        ret <- matrix(ret, ncol = length(ret)/nrow(newdata), \n            byrow = TRUE)\n    }\n    return(ret)\n}\n<environment: namespace:xgboost>\n"
    ],
    "type" : [
        2,
        2,
        3,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2
    ]
}