{
    "collab_server" : "",
    "contents" : "library(xgboost)\nlibrary(dplyr)\n\n# load train features\ntrain = lapply(1:10, function(i){\n  read.csv(paste0('data/raw_data/public_data/train/',sprintf('%05d',i),'/columns.csv'))\n}) %>% do.call(rbind, .) %>% data.frame\n\n# load train target\ntraintarget = lapply(1:10, function(i){\n  read.csv(paste0('data/raw_data/public_data/train/',sprintf('%05d',i),'/targets.csv'))\n}) %>% do.call(rbind, .) %>% data.frame\n\ntrain = train[complete.cases(traintarget),]\ntraintarget = traintarget[complete.cases(traintarget),-(1:2)]\n\n# load test features\nsub = read.csv('data/raw_data/public_data/submission_uniform_baseline.csv') %>% data.table\ntest_nrows = sub[,by='record_id', max(end)]$V1 # 5-29 sec\n\ntest = lapply(11:882, function(i){\n  df = read.csv(paste0('data/raw_data/public_data/test/',sprintf('%05d',i),'/columns.csv'))\n  df = df[1:test_nrows[i-10], ]\n  return(df)\n}) %>% do.call(rbind, .) %>% data.frame\n\n# remove duplicate columns\nremDupcols <- function(data){\n  rem = which(!(names(data) %in% colnames(unique(as.matrix(data), MARGIN=2))))\n  return(rem)\n}\nrem = remDupcols(train)\ntrain = train[,-rem]\ntest = test[,-rem]\n\n# remove highly correlated features from data\nrequire(caret)\nremHighcor <- function(data, cutoff, ...){\n  data_cor <- cor(sapply(data, as.numeric), ...)\n  data_cor[is.na(data_cor)] <- 0\n  rem <- findCorrelation(data_cor, cutoff=cutoff, verbose=T)\n  return(rem)\n}\nrem = remHighcor(train, cutoff = 0.99, use='pairwise.complete.obs')\ntrain = train[,-rem]\ntest = test[,-rem]\n\nrm(rem, remHighcor, remDupcols, test_nrows, sub)\ngc()\n\n# xgboost CV\ncweights = c(1.35298455691,1.38684574053,1.59587388404,1.35318713948,0.347783666015,0.661081706198,1.04723628621,0.398865222651,\n             0.207586320237,1.50578335208,0.110181365961,1.07803284435,1.36560417316,1.17024113802,1.1933637414,1.1803704493,\n             1.34414875433,1.11683830693,1.08083910312,0.503152249073)\nparams = list(booster = 'gbtree',\n              objective = 'reg:logistic',\n              eta = 0.1, # \n              subsample=0.6,\n              colsample_bytree=0.9,\n              max_depth=4, \n              verbose=1,\n              silent=1,\n              nthread=3)\ndata <- lapply(1:20, function(c) xgb.DMatrix(data=data.matrix(train), label=as.numeric(traintarget[,c]), missing=NA))\nfolds = list(1:1753, 1754:3395, 3396:4911, 4912:6448, 6449:7955, 7956:9347, 9348:10852, 10853:12520, 12521:14345, 14346:16124)\nbooster_folds <- lapply(1:length(folds), function(k){\n  test = lapply(1:20, function(c) xgboost:::slice(data[[c]], folds[[k]]))\n  train = lapply(1:20, function(c) xgboost:::slice(data[[c]], unlist(folds[-k])))\n  booster = lapply(1:20, function(c) xgboost:::xgb.Booster(params = params, cachelist = list(train[[c]], test[[c]])))\n  res = list(train=train, test=test, booster=booster)\n  return(res)\n})\nBS <- function(preds, train){\n  labels = lapply(1:20, function(c) getinfo(train[[c]], 'label'))\n  err = lapply(1:20, function(c) sum(cweights[c]*(preds[[c]] - labels[[c]])^2)/length(labels[[c]]))\n  err = sum(unlist(err))\n  return(c('BS'=err))\n}\n\nnrounds= 100\n\ngc()\n\nfor(i in 1:nrounds){ # iterate over rounds\n  \n  #print(i)\n  \n  res = list() # list of 10 {train-BS,test-BS} pairs\n  \n  for( j in 1:length(booster_folds)){ # iterate over 10 folds\n    \n    fold = booster_folds[[j]]\n    \n    # update 20 dimentional dmatrix\n    succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(booster=fold$booster[[c]], dtrain=fold$train[[c]],iter= i - 1, obj=NULL))\n    \n    gc()\n    \n    # eval 20 dimentional dmatrix\n    preds_train = lapply(1:20, function(c) predict(fold$booster[[c]], fold$train[[c]]))\n    preds_test = lapply(1:20, function(c) predict(fold$booster[[c]], fold$test[[c]]))\n    \n    norm_train = colSums(do.call('rbind', preds_train))\n    norm_test = colSums(do.call('rbind', preds_test))\n    \n    preds_train = lapply(1:20, function(c) preds_train[[c]]/norm_train)\n    preds_test = lapply(1:20, function(c) preds_test[[c]]/norm_test)\n    \n    eval_train = BS(preds_train, fold$train); names(eval_train) = 'train-BS'\n    eval_test = BS(preds_test, fold$test); names(eval_test) = 'test-BS'\n    \n    gc()\n    rm( preds_train, preds_test, norm_train, norm_test)\n    \n    \n    res[[j]] = c(eval_train, eval_test)\n    gc()\n    \n  }\n  \n  res = do.call('rbind', res) %>% as.data.frame\n  res = c(mean(res[,1]), sd(res[,1]), mean(res[,2]), sd(res[,2]))\n  cat('[',i,'] ',res[1],'+',res[2],'  ',res[3],'+',res[4],'\\n', sep='')\n  \n  #hist[[i]] = res\n}\n# [70] 0.125181+0.001987844  0.1912817+0.02403459\n\n\n# xgboost\ngc()\ndtrain <- lapply(1:20, function(c) xgb.DMatrix(data=data.matrix(train), label=as.numeric(traintarget[,c]), missing=NA))\nbooster = lapply(1:20, function(c) xgboost:::xgb.Booster(params = params, cachelist = list(dtrain[[c]])))\nnrounds= 70\ngc()\nfor(i in 1:nrounds){ # iterate over rounds\n  print(i)\n  # update 20 dimentional dmatrix\n  succ = lapply(1:20, function(c) xgboost:::xgb.iter.update(booster=booster[[c]], dtrain=dtrain[[c]],iter= i - 1, obj=NULL))\n  gc()\n}\n\n# eval 20 dimentional dmatrix\ndtest <- xgb.DMatrix(data=data.matrix(test), missing=NA)\npreds_test = lapply(1:20, function(c) predict(booster[[c]], dtest))\nnorm_test = colSums(do.call('rbind', preds_test))\npreds_test = lapply(1:20, function(c) preds_test[[c]]/norm_test)\n\n# create submission\nsub = read.csv('data/raw_data/public_data/submission_uniform_baseline.csv') %>% data.table\nfor(i in 1:20){\n  sub[,i+3] = preds_test[[i]]\n}\n\nwrite.table(sub, 'data/working/subs/xgboost_default.csv', \n            col.names = T, row.names = F, quote=F, sep=',')\n\n# LB = 0.1760\n\n\n",
    "created" : 1469452979167.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "380930914",
    "id" : "82C6C13B",
    "lastKnownWriteTime" : 1469456740,
    "last_content_update" : 1469456740545,
    "path" : "~/SPHERE-Challenge/code/models/xgboost_default.R",
    "project_path" : "code/models/xgboost_default.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}